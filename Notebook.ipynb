{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c5aee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#NOTES\n",
    "########################################################\n",
    "#print the count that each unique set of binary values occur in the dataset\n",
    "#df2.value_counts()\n",
    "\n",
    "#so .iloc[[0]] gets the first row of the series\n",
    "#.index https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Index.html\n",
    "#toList() converts the index to a list with a tuple of the unique set of binary values\n",
    "#the first square brackets after the tolist selects the only item in the list\n",
    "#the second square brackets selects some item at that index in the tuple\n",
    "#df2.value_counts().iloc[[6]].index.tolist()[0][0]\n",
    "\n",
    "#gets the count that the first unique set of binary values occur in the dataset\n",
    "#df2.value_counts().iloc[0]\n",
    "\n",
    "#number of items in dictionary = len(a)\n",
    "#select one instance from the dictionary = a[0]\n",
    "#each instance in dictionary is a tuple = type(a[0])\n",
    "#_______________________________________________________\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a365c0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#IMPORTS\n",
    "########################################################\n",
    "#importing train_test_split to split the data with \n",
    "from sklearn.model_selection import train_test_split\n",
    "#importing pandas to manipulate data with\n",
    "import pandas as pd\n",
    "#importing resample to upsample any data that's in the minority\n",
    "from sklearn.utils import resample\n",
    "#https://stackoverflow.com/questions/12986272/how-do-i-compute-all-possibilities-for-an-array-of-numbers-bits-in-python-or-a\n",
    "from itertools import product\n",
    "#from unique_combinations import subsets\n",
    "import itertools\n",
    "import math\n",
    "#_______________________________________________________\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ac8da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#ALL UNIQUE N BITS GENERATION\n",
    "########################################################\n",
    "def allUniqueNBitsGen(df2):\n",
    "    #https://stackoverflow.com/questions/5036700/how-can-you-dynamically-create-variables\n",
    "    #blank dictionary to store all binary combinations\n",
    "    a = {}\n",
    "    \n",
    "    #countI represents the number of unique binary combinations generated\n",
    "    countI = 0\n",
    "    \n",
    "    #https://stackoverflow.com/questions/12986272/how-do-i-compute-all-possibilities-for-an-array-of-numbers-bits-in-python-or-a\n",
    "    #if product is set [1,0] all binary combinations will be sorted from all ones to all zeros\n",
    "    #repeat is the number of bits/binary numbers\n",
    "    #repeat is set to the number of columns because 2^numberOfColumns is the number of unique combinations of binary numbers\n",
    "    for i in product([1,0], repeat=len(df2.columns)):\n",
    "        \n",
    "        #dynamically creating variables to store every tuple binary combination\n",
    "        a[countI] = i\n",
    "        \n",
    "        #countI is iterated here, so that the first a[countI] is where countI = 0\n",
    "        countI = countI + 1\n",
    "        \n",
    "    return a\n",
    "#_______________________________________________________\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14a1a4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#CREATE NEW BLANK DATAFRAME WITH COLUMNS FROM DATAFRAME\n",
    "########################################################\n",
    "def newValueCountsFrame(df2):\n",
    "    #basically trying to re-create value counts (pandas function), but I want to include all columns (the ones that don't have a count)\n",
    "    #creating a new empty list to add all columns from original data frame + value count\n",
    "    df2_value_counts_columns = []\n",
    "    \n",
    "    #need to add all column names to new data frame\n",
    "    #adding each column name from the data frame to a list\n",
    "    for i in range(len(df2.columns)):\n",
    "        \n",
    "        df2_value_counts_columns.append(df2.columns.tolist()[i])\n",
    "        \n",
    "    #adding value count to new data frame columns\n",
    "    df2_value_counts_columns.append(\"Value Count\")\n",
    "    \n",
    "    #creating new value counts dataframe with columns collected\n",
    "    df2_value_counts = pd.DataFrame(columns = df2_value_counts_columns)\n",
    "    \n",
    "    return df2_value_counts\n",
    "#_______________________________________________________\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd7fb97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#FILL BLANK DATAFRAME WITH VALUE COUNTS AND INSTANCES\n",
    "########################################################\n",
    "#NOTE: (a [Post Filling], df2 [Post Filling], df2_value_counts [Post Filling])\n",
    "def valueCounts(a, df2, df2_value_counts, n, listLT, listLF, listLC):\n",
    "    \n",
    "    #for all the unique bits instances\n",
    "    #len(a) in outer loop because we're nested for looping between the 'a' dictionary and the df2.value_counts\n",
    "    for i in range(len(a)):\n",
    "        \n",
    "        #make sure to reset the flag after each iteration\n",
    "        #flag holds whether or not the actual value count for the instance was greater than 0\n",
    "        flag = False\n",
    "        \n",
    "        #this list is meant to hold the instance for the new value counts dataframe\n",
    "        #make sure to clear the row list each iteration\n",
    "        #need to initially set this to this because it's a list of a list\n",
    "        row = list(a[i])\n",
    "        \n",
    "        #for the number of bits in the current dictionary item\n",
    "        for k in range(len(df2.value_counts())):\n",
    "            \n",
    "            #tuples can be used like: is (1,0,0) == (1,0,0) and it will return true\n",
    "            #and (1,0,0) == (0,1,0) will return false\n",
    "            if df2.value_counts().iloc[[k]].index.tolist()[0] == a[i]:\n",
    "                \n",
    "                #if these match, value count for actual dataframe instance is greater than 0\n",
    "                flag = True\n",
    "                \n",
    "                #append the value count of the dataframe to the new value counts\n",
    "                #keeps me from needing to figure out how to actually count the number of times it occurs\n",
    "                row.append(df2.value_counts().iloc[k])\n",
    "                \n",
    "        #if the value count was not greater than 0\n",
    "        if flag == False:\n",
    "            \n",
    "            #append that to the row\n",
    "            row.append(0)\n",
    "            \n",
    "        #add instance to new value counts\n",
    "        df2_value_counts.loc[i] = row\n",
    "        \n",
    "    #TESTING\n",
    "    #print(df2_value_counts)\n",
    "    rule(df2, df2_value_counts, n, listLT, listLF, listLC)\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa25598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#RULE CREATION PART\n",
    "########################################################\n",
    "def rule(df2, df2_value_counts, n, listLT, listLF, listLC):\n",
    "    \n",
    "    #list1 stores all of the rules for the data frame\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    \n",
    "    #PRNR stores the positive relationships in the dataframe and negative relationships from the data frame\n",
    "    #rainbow single colors in the order in which they occur, the size of PRNR is half of the size of the \n",
    "    #value counts of the dataframe\n",
    "    PRNR = {}\n",
    "    \n",
    "    numberOfInstances = len(df2)\n",
    "    \n",
    "    maxPRNR = 0\n",
    "    indexMaxPRNR = 0\n",
    "    maxPosPredVC = 0\n",
    "    indexMaxPosPredVC = 0\n",
    "    maxNegPredVC = 0\n",
    "    indexMaxNegPredVC = 0\n",
    "    \n",
    "    #number of unique value counts for a given data frame is 2 to the n where n is the number of columns\n",
    "    for i in range(pow(2, n)):\n",
    "        \n",
    "        #POSITIVE PREDICTION HEURISTIC INDEXING LOGIC\n",
    "        #in the value counts dataframe, all even rows contain a positive label\n",
    "        if i % 2 == 0:\n",
    "            ########################################################\n",
    "            #print(\"POSITIVE!\")\n",
    "            #print(df2_value_counts.iloc[[i]])\n",
    "            #print(\"--------------------------\")\n",
    "            #print()\n",
    "            ########################################################\n",
    "            \n",
    "            if maxPosPredVC < df2_value_counts.iloc[[i]][\"Value Count\"].values[0]:\n",
    "                maxPosPredVC = df2_value_counts.iloc[[i]][\"Value Count\"].values[0]\n",
    "                indexMaxPosPredVC = i\n",
    "        \n",
    "        #NEGATIVE PREDICTION HEURISTIC INDEXING LOGIC\n",
    "        #in the value counts dataframe, all odd rows contain a negative label\n",
    "        if i % 2 == 1:\n",
    "            ########################################################\n",
    "            #print(\"NEGATIVE!\")\n",
    "            #print(df2_value_counts.iloc[[i]])\n",
    "            #print(\"--------------------------\")\n",
    "            #print()\n",
    "            ########################################################\n",
    "            \n",
    "            if maxNegPredVC < df2_value_counts.iloc[[i]][\"Value Count\"].values[0]:\n",
    "                maxNegPredVC = df2_value_counts.iloc[[i]][\"Value Count\"].values[0]\n",
    "                indexMaxNegPredVC = i\n",
    "        \n",
    "        #COMBINATORIAL PREDICTION HEURISTIC INDEXING LOGIC\n",
    "        #in the value counts dataframe, all rows ((pow(2, n) - 1) - index of row < (pow(2,n/2))) away from\n",
    "        #any given index of a row less than (pow(2,n/2)) is the inverse of that row\n",
    "        if i < (pow(2, n)/2):\n",
    "            ########################################################\n",
    "            #print(\"COMBINATORIAL!\")\n",
    "            #print(df2_value_counts.iloc[[i]])\n",
    "            #print(df2_value_counts.iloc[[((pow(2, n) - 1) - i)]])\n",
    "            #print(\"--------------------------\")\n",
    "            #print()\n",
    "            ########################################################\n",
    "            \n",
    "            #PRNR logic AKA POS if X, NEG if -X, or POS if -X, NEG if X\n",
    "            #for brevity's sake\n",
    "            k = df2_value_counts.iloc[[i]][\"Value Count\"].values[0]\n",
    "            #need to collect the corresponding value column for k by the definition of P.R and N.R\n",
    "            #this can be accomplished with the formula below i.e. formula gets second number (0,7)(1,6)(2,5)(3,4) \n",
    "            #where n = 3 \n",
    "            z = ((pow(2, n) - 1) - i)\n",
    "            x = df2_value_counts.iloc[[z]][\"Value Count\"].values[0]\n",
    "            PRNR[i] = k + x\n",
    "            #the idea here is that, x and k combined need to represent more than 50% of the dataset to mean anything\n",
    "            #worthy of note\n",
    "            if x/numberOfInstances > 0.25 and k/numberOfInstances > 0.25:\n",
    "                if PRNR[i] > maxPRNR:\n",
    "                    maxPRNR = PRNR[i]\n",
    "                    indexMaxPRNR = i\n",
    "                \n",
    "            list2.append([i, z])\n",
    "            \n",
    "    #if there exists no PRNR relationship > 50% for the dataframe\n",
    "    if maxPRNR == 0:\n",
    "        \n",
    "        #if there exists a positive prediction value count for the dataframe\n",
    "        if maxPosPredVC != 0:\n",
    "\n",
    "            #subtract 1 for computer science numbering and another 1 to get past the value counts\n",
    "            labelName = df2_value_counts.iloc[[indexMaxPosPredVC]].columns[len(df2_value_counts.iloc[0]) - 2]\n",
    "\n",
    "            first = df2_value_counts.iloc[[indexMaxPosPredVC]]\n",
    "            combinedRule = \"\"\n",
    "\n",
    "            combinedRule = combinedRule + 'The heuristic \"If '\n",
    "\n",
    "            for z in range(len(df2_value_counts.columns) - 2):\n",
    "                columnName = first.columns[z]\n",
    "                columnNameValAtIndex = first[columnName].values[0]\n",
    "\n",
    "                if((len(df2_value_counts.columns) - 2) >= 3 and z == len(df2_value_counts.columns) - 3):\n",
    "                    if columnNameValAtIndex == 1:\n",
    "                        combinedRule = combinedRule + \"and \" + str(columnName) + \" is true; \"\n",
    "                    elif columnNameValAtIndex == 0:\n",
    "                        combinedRule = combinedRule + \"and \" + str(columnName) + \" is false; \"\n",
    "                elif (len(df2_value_counts.columns) - 2) == 2 and z == 0:\n",
    "                    if columnNameValAtIndex == 1:\n",
    "                        combinedRule = combinedRule + str(columnName) + \" is true and \"\n",
    "                    elif columnNameValAtIndex == 0:\n",
    "                        combinedRule = combinedRule + str(columnName) + \" is false and \"\n",
    "                else:\n",
    "                    if columnNameValAtIndex == 1:\n",
    "                        combinedRule = combinedRule + str(columnName) + \" is true, \"\n",
    "                    elif columnNameValAtIndex == 0:\n",
    "                        combinedRule = combinedRule + str(columnName) + \" is false, \"\n",
    "\n",
    "            labelNameValAtIndex = first[labelName].values[0]\n",
    "\n",
    "            instanceValueCounts = first[\"Value Count\"].values[0]\n",
    "\n",
    "            if labelNameValAtIndex == 1:\n",
    "                combinedRule = combinedRule + \"then \" + str(labelName) + ' is true.\" correctly labels ' + str((instanceValueCounts/numberOfInstances) * 100) + \"% of the instances in the sub-dataset, incorrectly labeling \" + str(numberOfInstances - instanceValueCounts) + \" of the \" + str(numberOfInstances) + \".\"\n",
    "                #print()\n",
    "                #print(combinedRule)\n",
    "                list1 = labelName, df2_value_counts.columns, combinedRule, (instanceValueCounts/numberOfInstances) * 100, df2_value_counts, df2\n",
    "                #print()\n",
    "\n",
    "            if labelNameValAtIndex == 0:\n",
    "                combinedRule = combinedRule + \"then \" + str(labelName) + ' is false.\" correctly labels ' + str((instanceValueCounts/numberOfInstances) * 100) + \"% of the instances in the sub-dataset, incorrectly labeling \" + str(numberOfInstances - instanceValueCounts) + \" of the \" + str(numberOfInstances) + \".\"\n",
    "                #print()\n",
    "                #print(combinedRule)\n",
    "                list1 = labelName, df2_value_counts.columns, combinedRule, (instanceValueCounts/numberOfInstances) * 100, df2_value_counts, df2\n",
    "                #print()\n",
    "\n",
    "            listLT.append(list1)\n",
    "\n",
    "        #if there exists a largest negative prediction value count for the dataframe\n",
    "        if maxNegPredVC != 0:\n",
    "            labelName = df2_value_counts.iloc[[indexMaxNegPredVC]].columns[len(df2_value_counts.iloc[0]) - 2]\n",
    "\n",
    "            first = df2_value_counts.iloc[[indexMaxNegPredVC]]\n",
    "            combinedRule = \"\"\n",
    "\n",
    "            combinedRule = combinedRule + 'The heuristic \"If '\n",
    "\n",
    "            for z in range(len(df2_value_counts.columns) - 2):\n",
    "                columnName = first.columns[z]\n",
    "                columnNameValAtIndex = first[columnName].values[0]\n",
    "\n",
    "                if((len(df2_value_counts.columns) - 2) >= 3 and z == len(df2_value_counts.columns) - 3):\n",
    "                    if columnNameValAtIndex == 1:\n",
    "                        combinedRule = combinedRule + \"and \" + str(columnName) + \" is true; \"\n",
    "                    elif columnNameValAtIndex == 0:\n",
    "                        combinedRule = combinedRule + \"and \" + str(columnName) + \" is false; \"\n",
    "                elif (len(df2_value_counts.columns) - 2) == 2 and z == 0:\n",
    "                    if columnNameValAtIndex == 1:\n",
    "                        combinedRule = combinedRule + str(columnName) + \" is true and \"\n",
    "                    elif columnNameValAtIndex == 0:\n",
    "                        combinedRule = combinedRule + str(columnName) + \" is false and \"\n",
    "                else:\n",
    "                    if columnNameValAtIndex == 1:\n",
    "                        combinedRule = combinedRule + str(columnName) + \" is true, \"\n",
    "                    elif columnNameValAtIndex == 0:\n",
    "                        combinedRule = combinedRule + str(columnName) + \" is false, \"\n",
    "\n",
    "            labelNameValAtIndex = first[labelName].values[0]\n",
    "\n",
    "            instanceValueCounts = first[\"Value Count\"].values[0]\n",
    "\n",
    "            if labelNameValAtIndex == 1:\n",
    "                combinedRule = combinedRule + \"then \" + str(labelName) + ' is true.\" correctly labels ' + str((instanceValueCounts/numberOfInstances) * 100) + \"% of the instances in the sub-dataset, incorrectly labeling \" + str(numberOfInstances - instanceValueCounts) + \" of the \" + str(numberOfInstances) + \".\"\n",
    "                #print()\n",
    "                #print(combinedRule)\n",
    "                list1 = labelName, df2_value_counts.columns, combinedRule, (instanceValueCounts/numberOfInstances) * 100, df2_value_counts, df2\n",
    "                #print()\n",
    "\n",
    "            if labelNameValAtIndex == 0:\n",
    "                combinedRule = combinedRule + \"then \" + str(labelName) + ' is false.\" correctly labels ' + str((instanceValueCounts/numberOfInstances) * 100) + \"% of the instances in the sub-dataset, incorrectly labeling \" + str(numberOfInstances - instanceValueCounts) + \" of the \" + str(numberOfInstances) + \".\"\n",
    "                #print()\n",
    "                #print(combinedRule)\n",
    "                list1 = labelName, df2_value_counts.columns, combinedRule, (instanceValueCounts/numberOfInstances) * 100, df2_value_counts, df2\n",
    "                #print()\n",
    "\n",
    "            listLF.append(list1)\n",
    "    \n",
    "    #if there exists a PRNR relationship > 50% for the dataframe\n",
    "    else:\n",
    "\n",
    "        labelName = df2_value_counts.iloc[[indexMaxPRNR]].columns[len(df2_value_counts.iloc[0]) - 2]\n",
    "        \n",
    "        #print(df2_value_counts.head())\n",
    "        #print(\"-----------------------\")\n",
    "        #print()\n",
    "\n",
    "        first = df2_value_counts.iloc[[list2[indexMaxPRNR][0]]]\n",
    "        second = df2_value_counts.iloc[[list2[indexMaxPRNR][1]]]\n",
    "        combinedRule = \"\"\n",
    "\n",
    "        #print(\"labelName = \", labelName)\n",
    "\n",
    "        combinedRule = combinedRule + 'The heuristic \"If '\n",
    "\n",
    "        for j in range(len(list2[indexMaxPRNR])):\n",
    "\n",
    "            for z in range(len(df2_value_counts.columns) - 2):\n",
    "\n",
    "                columnName = df2_value_counts.iloc[[list2[indexMaxPRNR][j]]].columns[z]\n",
    "                columnNameValAtIndex = df2_value_counts.iloc[[list2[indexMaxPRNR][j]]][columnName].values[0]\n",
    "\n",
    "                if((len(df2_value_counts.columns) - 2) >= 3 and z == len(df2_value_counts.columns) - 3):\n",
    "                    if columnNameValAtIndex == 1:\n",
    "                        combinedRule = combinedRule + \"and \" + str(columnName) + \" is true; \"\n",
    "                    elif columnNameValAtIndex == 0:\n",
    "                        combinedRule = combinedRule + \"and \" + str(columnName) + \" is false; \"\n",
    "                elif (len(df2_value_counts.columns) - 2) == 2 and z == 0:\n",
    "                    if columnNameValAtIndex == 1:\n",
    "                        combinedRule = combinedRule + str(columnName) + \" is true and \"\n",
    "                    elif columnNameValAtIndex == 0:\n",
    "                        combinedRule = combinedRule + str(columnName) + \" is false and \"\n",
    "                else:\n",
    "                    if columnNameValAtIndex == 1:\n",
    "                        combinedRule = combinedRule + str(columnName) + \" is true, \"\n",
    "                    elif columnNameValAtIndex == 0:\n",
    "                        combinedRule = combinedRule + str(columnName) + \" is false, \"\n",
    "\n",
    "            labelNameValAtIndex = df2_value_counts.iloc[[list2[indexMaxPRNR][j]]][labelName].values[0]\n",
    "            instanceValueCounts = df2_value_counts.iloc[[list2[indexMaxPRNR][j]]][\"Value Count\"].values[0]\n",
    "\n",
    "            if j == 0:\n",
    "                if labelNameValAtIndex == 1:\n",
    "                    combinedRule = combinedRule + \"then \"+ str(labelName) + ' is true.\" correctly labels ' + str((instanceValueCounts/numberOfInstances) * 100) + \"% of the instances, \"\n",
    "\n",
    "                if labelNameValAtIndex == 0:\n",
    "                    combinedRule = combinedRule + \"then \" + str(labelName) + ' is false.\" correctly labels ' + str((instanceValueCounts/numberOfInstances) * 100) + \"% of the instances, \"\n",
    "            else:\n",
    "                if labelNameValAtIndex == 1:\n",
    "                    combinedRule = combinedRule + \"then \" + str(labelName) + ' is true.\" correctly labels ' + str((instanceValueCounts/numberOfInstances) * 100) + \"% of the instances\"\n",
    "\n",
    "                if labelNameValAtIndex == 0:\n",
    "                    combinedRule = combinedRule + \"then \" + str(labelName) + ' is false.\" correctly labels ' + str((instanceValueCounts/numberOfInstances) * 100) + \"% of the instances\"\n",
    "\n",
    "            if(j != len(list2[indexMaxPRNR]) - 1):\n",
    "                combinedRule = combinedRule + 'and the heuristic \"If '\n",
    "\n",
    "            else:\n",
    "                combinedRule = combinedRule + \", for a combined rule accuracy of \" + str((PRNR[indexMaxPRNR]/numberOfInstances) * 100) + \"%, incorrectly labeling \" + str(numberOfInstances - PRNR[indexMaxPRNR]) + \" of the \" + str(numberOfInstances) + \" instances in the sub-dataset.\"\n",
    "                #print()\n",
    "                #print(combinedRule)\n",
    "                list1 = labelName, df2_value_counts.columns, combinedRule, (PRNR[indexMaxPRNR]/numberOfInstances) * 100, df2_value_counts, df2\n",
    "                #print()\n",
    "\n",
    "        listLC.append(list1)\n",
    "\n",
    "    #TESTING\n",
    "    #print(\"PRNR = \", PRNR)\n",
    "#_______________________________________________________\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f2cd05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#SORT AND PRINT\n",
    "########################################################\n",
    "#https://www.delftstack.com/howto/python/sort-list-of-lists-in-python/\n",
    "def sortAndPrint(listListLists):\n",
    "    from operator import itemgetter\n",
    "    print()\n",
    "    print(\"Best Heuristics for All Sub-Datasets:\")\n",
    "    print(\"_____________________________________\")\n",
    "    print()\n",
    "    \n",
    "    sortedListLists = []\n",
    "    \n",
    "    for i in range(len(listListLists)): #for each label iterated through\n",
    "            \n",
    "        sortedListLists = sorted(listListLists[i], key=itemgetter(3), reverse=True)\n",
    "        print(\"The Best Rule for Label\", sortedListLists[0][0])\n",
    "        print(\"-------------------------\")\n",
    "        print(sortedListLists[0][2]) #at index 2 is the rule\n",
    "        print(sortedListLists[0][4])\n",
    "        print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "581f7faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#HONETSCHLAGER'S METHOD (CATEGORICAL DATAFRAME)\n",
    "########################################################\n",
    "from operator import itemgetter\n",
    "def honetschlagersMethod2(n, df, df_initial):\n",
    "    #to store variables printed from the method\n",
    "    #this needs to be set way at the outset so that the variable doesn't \n",
    "    #get wiped/reset, so that we store everything output\n",
    "    \n",
    "    listListLists = []\n",
    "    #THE NUMBER OF TOTAL COLUMNS (AFTER Y) NEEDS TO BE \n",
    "    #GREATER THAN OR EQUAL TO 2\n",
    "    #n is number of unique columns\n",
    "    n = n\n",
    "    \n",
    "    #for all columns in the initial un-dummied data set\n",
    "    for (columnName, columnData) in df_initial.iteritems():\n",
    "        \n",
    "        print(columnName)\n",
    "        parentColumnName = columnName\n",
    "        \n",
    "        for (columnName, columnData) in df.iteritems():\n",
    "            \n",
    "            #because for loop starts from beginning of df, need to make sure we have the parent's child\n",
    "            if parentColumnName in columnName:\n",
    "                y = df[columnName]\n",
    "                y_columnName = columnName\n",
    "                \n",
    "                X = df\n",
    "\n",
    "                for (columnName, columnData) in df.iteritems():\n",
    "                    #check if the parent column name is present in the dummy column name\n",
    "                    #this ensures we're specifying one parent column to pull our y vector or labels from\n",
    "                    if parentColumnName in columnName:\n",
    "\n",
    "                        X = X.drop(columnName, axis=1)\n",
    "                        \n",
    "                #list of label true rule instance details\n",
    "                listLT = []\n",
    "                \n",
    "                #list of label false rule instance details\n",
    "                listLF = []\n",
    "                \n",
    "                #list of combinatorial label rule instance details\n",
    "                listLC = []\n",
    "\n",
    "                #all unique combinations of columns in the dataframe\n",
    "                unique_combinations_listI = list(itertools.combinations(X.columns, n))\n",
    "\n",
    "                #for all tuples in the list of tuples\n",
    "                for i in range(len(unique_combinations_listI)):\n",
    "\n",
    "                    #need to initiate data frame with a place holder column name so we can easily insert columns into the dataframe\n",
    "                    df_test = pd.DataFrame(columns = ['a'])\n",
    "\n",
    "                    #for every item inside the current tuple except for y, which will be the last item in the tuple hence - 1\n",
    "                    for j in range(len(unique_combinations_listI[0])):\n",
    "\n",
    "                        #insert each column into our testing dataframe\n",
    "                        #insert(loc to insert the column, column name, data for the column)\n",
    "                        df_test.insert(j, unique_combinations_listI[i][j], df[unique_combinations_listI[i][j]])\n",
    "\n",
    "                    #TESTING\n",
    "                    #print()\n",
    "                    #let the user know what label we're working on\n",
    "                    #print('Label: ' + y.name)\n",
    "                    #print()\n",
    "\n",
    "                    #insert y at the end of the test dataframe\n",
    "                    df_test.insert(len(df_test.columns), y.name, y)\n",
    "\n",
    "                    #pop column a as it's no longer needed\n",
    "                    df_test.pop('a')\n",
    "\n",
    "                    #add 1 to n because in the value counts method we refer to n as though it's the number of unique\n",
    "                    #columns in the testing dataframe and not just in the x vector\n",
    "                    valueCounts(allUniqueNBitsGen(df_test), df_test, newValueCountsFrame(df_test), n + 1, listLT, listLF, listLC)\n",
    "                \n",
    "                if len(listLT) > 0:\n",
    "                    listLT = sorted(listLT, key=itemgetter(3), reverse=True)\n",
    "                    print('The Best Rule for \"label', \"'\" , listLF[0][0], \"'\", 'is true\"')\n",
    "                    print(\"------------------------------------------------------\")\n",
    "                    print(listLT[0][2]) #at index 2 is the rule\n",
    "                    print()\n",
    "                    print(\"Value Counts for Sub-Dataset: \")\n",
    "                    print(listLT[0][4])\n",
    "                    #print(listLT)\n",
    "                    print()\n",
    "\n",
    "                if len(listLF) > 0:\n",
    "                    listLF = sorted(listLF, key=itemgetter(3), reverse=True)\n",
    "                    print('The Best Rule for \"label', \"'\", listLF[0][0], \"'\", 'is false\"')\n",
    "                    print(\"-------------------------------------------------------\")\n",
    "                    print(listLF[0][2]) #at index 2 is the rule\n",
    "                    print()\n",
    "                    print(\"Value Counts for Sub-Dataset: \")\n",
    "                    print(listLF[0][4])\n",
    "                    print()\n",
    "\n",
    "                if len(listLC) > 0:\n",
    "                    listLC = sorted(listLC, key=itemgetter(3), reverse=True)\n",
    "                    print(\"The Best Combinatorial Rule for Label '\", listLC[0][0], \"'\")\n",
    "                    print(\"----------------------------------------------------\")\n",
    "                    print(listLC[0][2]) #at index 2 is the rule\n",
    "                    print()\n",
    "                    print(\"Value Counts for Sub-Dataset: \")\n",
    "                    print(listLC[0][4])\n",
    "                    print()\n",
    "\n",
    "\n",
    "            #TESTING\n",
    "            #print()\n",
    "            #print(\"------------------------------------------------\")\n",
    "    #sortAndPrint(listListLists)\n",
    "#_______________________________________________________\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18c1d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#HONETSCHLAGER'S METHOD (BINARY DATAFRAME NO PARENTS)\n",
    "########################################################\n",
    "from operator import itemgetter\n",
    "def honetschlagersMethod(n, df):\n",
    "    #to store variables printed from the method\n",
    "    #this needs to be set way at the outset so that the variable doesn't \n",
    "    #get wiped/reset, so that we store everything output\n",
    "    \n",
    "    listListLists = []\n",
    "    #THE NUMBER OF TOTAL COLUMNS (AFTER Y) NEEDS TO BE \n",
    "    #GREATER THAN OR EQUAL TO 2\n",
    "    #n is number of unique columns\n",
    "    n = n\n",
    "    \n",
    "    for (columnName, columnData) in df.iteritems():\n",
    "        \n",
    "        #list of label true rule instance details\n",
    "        listLT = []\n",
    "\n",
    "        #list of label false rule instance details\n",
    "        listLF = []\n",
    "\n",
    "        #list of combinatorial label rule instance details\n",
    "        listLC = []\n",
    "        \n",
    "        y = df[columnName]\n",
    "        X = df.drop(columnName, axis=1)\n",
    "        \n",
    "        #all unique combinations of columns in the dataframe\n",
    "        unique_combinations_listI = list(itertools.combinations(X.columns, n))\n",
    "\n",
    "        #for all tuples in the list of tuples\n",
    "        for i in range(len(unique_combinations_listI)):\n",
    "            df_resampled = pd.DataFrame()\n",
    "\n",
    "            #need to initiate data frame with a place holder column name so we can easily insert columns into the dataframe\n",
    "            df_test = pd.DataFrame(columns = ['a'])\n",
    "\n",
    "            #for every item inside the current tuple except for y, which will be the last item in the tuple hence - 1\n",
    "            for j in range(len(unique_combinations_listI[0])):\n",
    "\n",
    "                #insert each column into our testing dataframe\n",
    "                #insert(loc to insert the column, column name, data for the column)\n",
    "                df_test.insert(j, unique_combinations_listI[i][j], df[unique_combinations_listI[i][j]])\n",
    "\n",
    "            #TESTING\n",
    "            #print()\n",
    "            #let the user know what label we're working on\n",
    "            #print('Label: ' + y.name)\n",
    "            #print()\n",
    "\n",
    "            #insert y at the end of the test dataframe\n",
    "            df_test.insert(len(df_test.columns), y.name, y)\n",
    "            \n",
    "            #pop column a as it's no longer needed\n",
    "            df_test.pop('a')\n",
    "\n",
    "            #UPSAMPLING\n",
    "            #resample the dataframe_skip to equal the value counts of columns with 0\n",
    "            #n_samples = df_dummies[skip].value_counts().max(), replace = True) #old n samples statement\n",
    "            df_resampled = resample(df_test[df_test[y.name] == 0], n_samples = 200, replace = True)\n",
    "            #apppend the columns with 1\n",
    "            df_resampled = df_resampled.append(resample(df_test[df_test[y.name] == 1], n_samples = 200, replace = True))\n",
    "            df_resampled = df_resampled.sample(frac = 1).reset_index(drop=True)\n",
    "            \n",
    "            #NO UPSAMPLING\n",
    "            ###df_resampled = df_test.sample(frac = 1).reset_index(drop=True)\n",
    "\n",
    "            #add 1 to n because in the value counts method we refer to n as though it's the number of unique\n",
    "            #columns in the testing dataframe and not just in the x vector\n",
    "            valueCounts(allUniqueNBitsGen(df_resampled), df_resampled, newValueCountsFrame(df_resampled), n + 1, listLT, listLF, listLC)\n",
    "        \n",
    "        if len(listLT) > 0:\n",
    "            listLT = sorted(listLT, key=itemgetter(3), reverse=True)\n",
    "            print('The Best Rule for \"label', \"'\" , listLF[0][0], \"'\", 'is true\"')\n",
    "            print(\"------------------------------------------------------\")\n",
    "            print(listLT[0][2]) #at index 2 is the rule\n",
    "            print()\n",
    "            print(\"Value Counts for Sub-Dataset: \")\n",
    "            print(listLT[0][4])\n",
    "            #print(listLT)\n",
    "            print()\n",
    "\n",
    "        if len(listLF) > 0:\n",
    "            listLF = sorted(listLF, key=itemgetter(3), reverse=True)\n",
    "            print('The Best Rule for \"label', \"'\", listLF[0][0], \"'\", 'is false\"')\n",
    "            print(\"-------------------------------------------------------\")\n",
    "            print(listLF[0][2]) #at index 2 is the rule\n",
    "            print()\n",
    "            print(\"Value Counts for Sub-Dataset: \")\n",
    "            print(listLF[0][4])\n",
    "            print()\n",
    "\n",
    "        if len(listLC) > 0:\n",
    "            listLC = sorted(listLC, key=itemgetter(3), reverse=True)\n",
    "            print(\"The Best Combinatorial Rule for Label '\", listLC[0][0], \"'\")\n",
    "            print(\"----------------------------------------------------\")\n",
    "            print(listLC[0][2]) #at index 2 is the rule\n",
    "            print()\n",
    "            print(\"Value Counts for Sub-Dataset: \")\n",
    "            print(listLC[0][4])\n",
    "            print()\n",
    "        \n",
    "        #TESTING\n",
    "        #print()\n",
    "        #print(\"------------------------------------------------\")\n",
    "    #sortAndPrint(listListLists)\n",
    "#_______________________________________________________\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a2965fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    ########################################################\n",
    "    #for a dataframe that's already in binary/no parents\n",
    "    ########################################################\n",
    "    #I collect the non-dummy data incase it's necessary to have it\n",
    "    #sample shuffles the data\n",
    "    #reset_index resets the numbering on the side of the instances, to remove traces of shuffling\n",
    "    #must have 2 or more columns\n",
    "    df = pd.read_excel(\"Data\\\\XYZ.xlsx\").sample(frac=1).reset_index(drop=True)\n",
    "    df_initial = pd.DataFrame()\n",
    "    \n",
    "    ########################################################\n",
    "    #for a dataframe that's categorical with parents\n",
    "    ########################################################\n",
    "    #collecting data\n",
    "    #dropped survey year because it contains the same value, \"2013\", repeated for every instance in the data\n",
    "    #dropped three digit residential zip code because it contains too many categorical values for getting dummies\n",
    "    #I collect the non-dummy data incase it's necessary to have it\n",
    "    ###df_initial = pd.read_csv(\"Data\\\\Patient_Characteristics_Survey__PCS___2013.csv\").drop(['Survey Year', 'Three Digit Residential Zip Code'], axis=1)\n",
    "    #randomize the data frame and reset the index\n",
    "    ###df_initial = df_initial.sample(frac = 0.1).reset_index(drop=True)\n",
    "    #drops x columns from the beginning of the dataframe\n",
    "    #df_initial.drop(df_initial.columns[[range(x)]], axis = 1, inplace = True)\n",
    "    #print(\"len(df_initial.columns) = \", len(df_initial.columns))\n",
    "    ###print(df_initial.head())\n",
    "    #I collect the dummy data because I've been told it proves more useful\n",
    "    ###df = pd.get_dummies(df_initial)\n",
    "    #print(\"len(df_initial) =\", len(df_initial))\n",
    "    \n",
    "    userSelXVSize = int(input(\"Please enter the number of columns you'd like to have in the X-Vector: \"))\n",
    "    \n",
    "    while (userSelXVSize > len(df.columns)):\n",
    "        print()\n",
    "        print(\"Columns must be less than\", len(df.columns))\n",
    "        print()\n",
    "        userSelXVSize = int(input(\"Please enter the number of columns you'd like to have in the X-Vector: \"))\n",
    "        \n",
    "    print()\n",
    "\n",
    "    if len(df_initial.columns) > 0:\n",
    "        #print(\"Dataset: \")\n",
    "        #print(df_initial)\n",
    "        #print()\n",
    "        #print(\"Dummied Dataset: \")\n",
    "        #print(df)\n",
    "        honetschlagersMethod2(userSelXVSize, df,df_initial)\n",
    "    else:\n",
    "        print(\"Dataset: \")\n",
    "        print(df)\n",
    "        print()\n",
    "        honetschlagersMethod(userSelXVSize, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e90a14b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the number of columns you'd like to have in the X-Vector: 1\n",
      "\n",
      "Dataset: \n",
      "      X    Y    Z\n",
      "0   1.0  1.0  1.0\n",
      "1   1.0  1.0  0.0\n",
      "2   NaN  NaN  NaN\n",
      "3   1.0  0.0  1.0\n",
      "4   NaN  NaN  NaN\n",
      "5   NaN  NaN  NaN\n",
      "6   NaN  NaN  NaN\n",
      "7   0.0  1.0  1.0\n",
      "8   1.0  0.0  1.0\n",
      "9   NaN  NaN  1.0\n",
      "10  1.0  1.0  0.0\n",
      "11  0.0  1.0  1.0\n",
      "12  0.0  1.0  0.0\n",
      "13  0.0  0.0  1.0\n",
      "14  NaN  NaN  NaN\n",
      "15  NaN  NaN  NaN\n",
      "16  1.0  1.0  1.0\n",
      "17  1.0  1.0  1.0\n",
      "18  0.0  0.0  1.0\n",
      "19  1.0  0.0  0.0\n",
      "20  0.0  0.0  1.0\n",
      "21  1.0  0.0  0.0\n",
      "22  0.0  1.0  0.0\n",
      "23  0.0  0.0  0.0\n",
      "24  1.0  1.0  0.0\n",
      "25  1.0  0.0  0.0\n",
      "26  0.0  1.0  0.0\n",
      "27  0.0  0.0  1.0\n",
      "28  NaN  NaN  NaN\n",
      "29  NaN  NaN  NaN\n",
      "30  1.0  1.0  1.0\n",
      "31  1.0  0.0  1.0\n",
      "32  0.0  0.0  1.0\n",
      "33  0.0  0.0  1.0\n",
      "34  NaN  NaN  NaN\n",
      "35  NaN  NaN  NaN\n",
      "36  1.0  1.0  1.0\n",
      "\n",
      "The Best Rule for \"label ' X ' is true\"\n",
      "------------------------------------------------------\n",
      "The heuristic \"If Z is true, then X is true.\" correctly labels 31.0% of the instances in the sub-dataset, incorrectly labeling 276 of the 400.\n",
      "\n",
      "Value Counts for Sub-Dataset: \n",
      "   Z  X  Value Count\n",
      "0  1  1          124\n",
      "1  1  0          144\n",
      "2  0  1           76\n",
      "3  0  0           56\n",
      "\n",
      "The Best Rule for \"label ' X ' is false\"\n",
      "-------------------------------------------------------\n",
      "The heuristic \"If Z is true, then X is false.\" correctly labels 36.0% of the instances in the sub-dataset, incorrectly labeling 256 of the 400.\n",
      "\n",
      "Value Counts for Sub-Dataset: \n",
      "   Z  X  Value Count\n",
      "0  1  1          124\n",
      "1  1  0          144\n",
      "2  0  1           76\n",
      "3  0  0           56\n",
      "\n",
      "The Best Combinatorial Rule for Label ' X '\n",
      "----------------------------------------------------\n",
      "The heuristic \"If Y is true, then X is true.\" correctly labels 31.0% of the instances, and the heuristic \"If Y is false, then X is false.\" correctly labels 28.999999999999996% of the instances, for a combined rule accuracy of 60.0%, incorrectly labeling 160 of the 400 instances in the sub-dataset.\n",
      "\n",
      "Value Counts for Sub-Dataset: \n",
      "   Y  X  Value Count\n",
      "0  1  1          124\n",
      "1  1  0           84\n",
      "2  0  1           76\n",
      "3  0  0          116\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kristopher\\AppData\\Local\\Temp\\ipykernel_3652\\1498903839.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_resampled = df_resampled.append(resample(df_test[df_test[y.name] == 1], n_samples = 200, replace = True))\n",
      "C:\\Users\\Kristopher\\AppData\\Local\\Temp\\ipykernel_3652\\1498903839.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_resampled = df_resampled.append(resample(df_test[df_test[y.name] == 1], n_samples = 200, replace = True))\n",
      "C:\\Users\\Kristopher\\AppData\\Local\\Temp\\ipykernel_3652\\1498903839.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_resampled = df_resampled.append(resample(df_test[df_test[y.name] == 1], n_samples = 200, replace = True))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Rule for \"label ' Y ' is true\"\n",
      "------------------------------------------------------\n",
      "The heuristic \"If Z is true, then Y is true.\" correctly labels 26.25% of the instances in the sub-dataset, incorrectly labeling 295 of the 400.\n",
      "\n",
      "Value Counts for Sub-Dataset: \n",
      "   Z  Y  Value Count\n",
      "0  1  1          105\n",
      "1  1  0          143\n",
      "2  0  1           95\n",
      "3  0  0           57\n",
      "\n",
      "The Best Rule for \"label ' Y ' is false\"\n",
      "-------------------------------------------------------\n",
      "The heuristic \"If Z is true, then Y is false.\" correctly labels 35.75% of the instances in the sub-dataset, incorrectly labeling 257 of the 400.\n",
      "\n",
      "Value Counts for Sub-Dataset: \n",
      "   Z  Y  Value Count\n",
      "0  1  1          105\n",
      "1  1  0          143\n",
      "2  0  1           95\n",
      "3  0  0           57\n",
      "\n",
      "The Best Combinatorial Rule for Label ' Y '\n",
      "----------------------------------------------------\n",
      "The heuristic \"If X is true, then Y is true.\" correctly labels 31.5% of the instances, and the heuristic \"If X is false, then Y is false.\" correctly labels 28.749999999999996% of the instances, for a combined rule accuracy of 60.25%, incorrectly labeling 159 of the 400 instances in the sub-dataset.\n",
      "\n",
      "Value Counts for Sub-Dataset: \n",
      "   X  Y  Value Count\n",
      "0  1  1          126\n",
      "1  1  0           85\n",
      "2  0  1           74\n",
      "3  0  0          115\n",
      "\n",
      "The Best Rule for \"label ' Z ' is true\"\n",
      "------------------------------------------------------\n",
      "The heuristic \"If X is true, then Z is true.\" correctly labels 28.499999999999996% of the instances in the sub-dataset, incorrectly labeling 286 of the 400.\n",
      "\n",
      "Value Counts for Sub-Dataset: \n",
      "   X  Z  Value Count\n",
      "0  1  1          114\n",
      "1  1  0          123\n",
      "2  0  1           74\n",
      "3  0  0           77\n",
      "\n",
      "The Best Rule for \"label ' Z ' is false\"\n",
      "-------------------------------------------------------\n",
      "The heuristic \"If Y is true, then Z is false.\" correctly labels 33.5% of the instances in the sub-dataset, incorrectly labeling 266 of the 400.\n",
      "\n",
      "Value Counts for Sub-Dataset: \n",
      "   Y  Z  Value Count\n",
      "0  1  1           94\n",
      "1  1  0          134\n",
      "2  0  1           94\n",
      "3  0  0           66\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kristopher\\AppData\\Local\\Temp\\ipykernel_3652\\1498903839.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_resampled = df_resampled.append(resample(df_test[df_test[y.name] == 1], n_samples = 200, replace = True))\n",
      "C:\\Users\\Kristopher\\AppData\\Local\\Temp\\ipykernel_3652\\1498903839.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_resampled = df_resampled.append(resample(df_test[df_test[y.name] == 1], n_samples = 200, replace = True))\n",
      "C:\\Users\\Kristopher\\AppData\\Local\\Temp\\ipykernel_3652\\1498903839.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_resampled = df_resampled.append(resample(df_test[df_test[y.name] == 1], n_samples = 200, replace = True))\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n",
    "    #skewed negative/positive count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
